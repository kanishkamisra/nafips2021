{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minicons.minicons import cwe\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_height_dataset(split = \"train\"):\n",
    "    dataset = []\n",
    "    with open(f\"../data/height_{split}.csv\", \"r\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(f)\n",
    "        for line in reader:\n",
    "            sentence, name, vs, s, m, t, vt = line\n",
    "            fuzziness = torch.tensor([float(x) for x in [vs, s, m, t, vt]])\n",
    "            dataset.append([(sentence, name), fuzziness])\n",
    "    return dataset\n",
    "            \n",
    "# height_train = load_height_dataset(\"train\")\n",
    "# height_test = load_height_dataset(\"test\")\n",
    "# height_dev = load_height_dataset(\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert =cwe.CWE(\"bert-base-uncased\", \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9993, -0.2315, -0.4809,  ...,  0.1523, -0.1126, -0.7785],\n",
       "        [ 0.3991, -0.0655,  0.1400,  ...,  0.5235,  0.1914, -0.5471],\n",
       "        [-0.9946,  0.8755, -0.5888,  ...,  0.1873,  2.0128,  0.3117],\n",
       "        ...,\n",
       "        [ 1.2157, -0.2108,  1.1080,  ...,  0.7018,  0.1657, -0.1995],\n",
       "        [ 0.2382,  1.1208,  0.4747,  ..., -0.0275, -0.6111, -1.2599],\n",
       "        [ 0.2843, -0.3253, -0.4962,  ...,  0.2942,  1.0745, -0.7884]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert.extract_representation([('Delilah is 61.37 cm tall.', 'Delilah'), (\"Roberto 's height is 61.38 cm.\", 'Roberto'), ('Bryan is 61.4 cm.', 'Bryan'), (\"Serena 's height is 61.41 cm.\", 'Serena'), ('Isabelle is 61.42 cm.', 'Isabelle'), ('Cathy is 61.43 cm tall.', 'Cathy'), ('Therese is 61.44 cm.', 'Therese'), ('Patty is 61.45 cm tall.', 'Patty'), ('Emanuel is 61.46 cm tall.', 'Emanuel'), (\"Edward 's height is 61.47 cm.\", 'Edward')], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1833)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.l1_loss(torch.tensor([[1.0,0.0,0.0], [0.0,1.0,0.0]]), torch.tensor([[0.9, 0.2, 0.1], [0.0, 1.0, 0.7]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeightProbe(pl.LightningModule):\n",
    "    def __init__(self, bert_layer = 1):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(768, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 5),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.layer = bert_layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        estimate = self.mlp(x)\n",
    "        return estimate\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defined the train loop.\n",
    "        # It is independent of forward\n",
    "        queries, fuzziness = batch\n",
    "        queries = list(zip(*queries))\n",
    "        representation = bert.extract_representation(queries, self.layer)\n",
    "        y_hat = self.mlp(representation)\n",
    "        loss = F.l1_loss(y_hat, fuzziness)\n",
    "        # Logging to TensorBoard by default\n",
    "        self.log('train_loss', loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        queries, fuzziness = batch\n",
    "        queries = list(zip(*queries))\n",
    "        representation = bert.extract_representation(queries, self.layer)\n",
    "        y_hat = self.mlp(representation)\n",
    "        loss = F.l1_loss(y_hat, fuzziness)\n",
    "        self.log('val_loss', loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeightDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size = 10, shuffle = False):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.train, self.val, self.test = load_height_dataset(\"train\"), load_height_dataset(\"dev\"), load_height_dataset(\"test\")\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train, batch_size=self.batch_size, shuffle=self.shuffle)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val, batch_size=self.batch_size, shuffle=self.shuffle)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test, batch_size=self.batch_size, shuffle=self.shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = HeightProbe(bert_layer = 10)\n",
    "height_data = HeightDataModule(shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/home/CIT/kmisra/miniconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: GPU available but not used. Set the --gpus flag when calling the script.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | mlp  | Sequential | 792 K \n",
      "------------------------------------\n",
      "792 K     Trainable params\n",
      "0         Non-trainable params\n",
      "792 K     Total params\n",
      "3.170     Total estimated model params size (MB)\n",
      "/home/CIT/kmisra/miniconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Your val_dataloader has `shuffle=True`, it is best practice to turn this off for validation and test dataloaders.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/CIT/kmisra/miniconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/CIT/kmisra/miniconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d634aebf10e1427e9519ff052ea69490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f2bd4739c9e4280a4ba86c07a21d96c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/CIT/kmisra/miniconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_steps=2000, val_check_interval=100)\n",
    "trainer.fit(hp, height_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.1932e-08, 2.9458e-09, 7.4915e-09, 1.4585e-09, 8.7141e-09]],\n",
       "       grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp(bert.extract_representation([\"Everett is 10 cm tall.\", \"Everett\"], 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
